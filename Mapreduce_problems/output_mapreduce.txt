[cloudera@quickstart ~]$ hadoop jar '/home/cloudera/UniqueUsers.jar'
Bindi/weblog.csv output
22/05/15 12:46:00 INFO client.RMProxy: Connecting to ResourceManager
at quickstart.cloudera/127.0.0.1:8032
22/05/15 12:46:04 WARN mapreduce.JobSubmitter: Hadoop command-line
option parsing not performed. Implement the Tool interface and execute
your application with ToolRunner to remedy this.
22/05/15 12:46:09 INFO input.FileInputFormat: Total input paths to process : 1
22/05/15 12:46:10 INFO mapreduce.JobSubmitter: number of splits:1
22/05/15 12:46:13 INFO mapreduce.JobSubmitter: Submitting tokens for
job: job_1652643101887_0003
22/05/15 12:46:16 INFO impl.YarnClientImpl: Submitted application
application_1652643101887_0003
22/05/15 12:46:17 INFO mapreduce.Job: The url to track the job:
http://quickstart.cloudera:8088/proxy/application_1652643101887_0003/
22/05/15 12:46:17 INFO mapreduce.Job: Running job: job_1652643101887_0003
22/05/15 12:47:04 INFO mapreduce.Job: Job job_1652643101887_0003
running in uber mode : false
22/05/15 12:47:04 INFO mapreduce.Job:  map 0% reduce 0%
22/05/15 12:47:55 INFO mapreduce.Job:  map 100% reduce 0%
22/05/15 12:48:21 INFO mapreduce.Job:  map 100% reduce 100%
22/05/15 12:48:22 INFO mapreduce.Job: Job job_1652643101887_0003
completed successfully
22/05/15 12:48:23 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=198
                FILE: Number of bytes written=228021
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=1115470
                HDFS: Number of bytes written=171
                HDFS: Number of read operations=6
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=1
                Launched reduce tasks=1
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=3540864
                Total time spent by all reduces in occupied slots (ms)=3097984
                Total time spent by all map tasks (ms)=27663
                Total time spent by all reduce tasks (ms)=24203
                Total vcore-seconds taken by all map tasks=27663
                Total vcore-seconds taken by all reduce tasks=24203
                Total megabyte-seconds taken by all map tasks=3540864
                Total megabyte-seconds taken by all reduce tasks=3097984
        Map-Reduce Framework
                Map input records=16008
                Map output records=16008
                Map output bytes=238943
                Map output materialized bytes=194
                Input split bytes=127
                Combine input records=16008
                Combine output records=17
                Reduce input groups=17
                Reduce shuffle bytes=194
                Reduce input records=17
                Reduce output records=17
                Spilled Records=34
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=478
                CPU time spent (ms)=4100
                Physical memory (bytes) snapshot=267579392
                Virtual memory (bytes) snapshot=1412378624
                Total committed heap usage (bytes)=101449728
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=1115343
        File Output Format Counters
                Bytes Written=171
[cloudera@quickstart ~]$ hadoop fs -cat output/part-r-00000
10.128.2.1      4257
10.129.2.1      1652
10.130.2.1      4056
10.131.0.1      4198
10.131.2.1      1626
IP      1
[Fri    1
[Mon    5
[Sat    1
[Thu    6
[Tue    17
[Wed    5
a.out:  4
chmod:  95
rm:     72
sh:     7
timeout:        5
[cloudera@quickstart ~]$ hadoop fs -cat output/part-r-00000
^C[cloudera@quickstart ~]$ hadoop jar '/home/cloudera/UniqueUsers.jar'
Bindi/webg.csv output
22/05/15 12:59:33 INFO client.RMProxy: Connecting to ResourceManager
at quickstart.cloudera/127.0.0.1:8032
22/05/15 12:59:35 WARN security.UserGroupInformation:
PriviledgedActionException as:cloudera (auth:SIMPLE)
cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output
directory hdfs://quickstart.cloudera:8020/user/cloudera/output already
exists
Exception in thread "main"
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory
hdfs://quickstart.cloudera:8020/user/cloudera/output already exists
        at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:562)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:432)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1306)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1303)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1303)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1324)
        at UniqueUsers.main(UniqueUsers.java:67)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[cloudera@quickstart ~]$ hadoop jar '/home/cloudera/UniqueUsers.jar'
Bindi/weblog.csv output1

22/05/15 13:01:13 INFO client.RMProxy: Connecting to ResourceManager
at quickstart.cloudera/127.0.0.1:8032
[cloudera@quickstart ~]$ hadoop fs -cat output1/part-r-0000010.128.2.1  4257
10.129.2.1      1652
10.130.2.1      4056
10.131.0.1      4198
10.131.2.1      1626
[cloudera@quickstart ~]$ hadoop jar '/home/cloudera/MaxCount.jar'
output1/part-r-00000 output2
[cloudera@quickstart ~]$ hadoop jar '/home/cloudera/MaxCount.jar'
output1/part-r-00000 output2
22/05/15 13:06:17 INFO client.RMProxy: Connecting to ResourceManager
at quickstart.cloudera/127.0.0.1:8032
22/05/15 13:06:22 WARN mapreduce.JobSubmitter: Hadoop command-line
option parsing not performed. Implement the Tool interface and execute
your application with ToolRunner to remedy this.
22/05/15 13:06:27 INFO input.FileInputFormat: Total input paths to process : 1
22/05/15 13:06:28 INFO mapreduce.JobSubmitter: number of splits:1
22/05/15 13:06:29 INFO mapreduce.JobSubmitter: Submitting tokens for
job: job_1652643101887_0005
22/05/15 13:06:31 INFO impl.YarnClientImpl: Submitted application
application_1652643101887_0005
22/05/15 13:06:32 INFO mapreduce.Job: The url to track the job:
http://quickstart.cloudera:8088/proxy/application_1652643101887_0005/
22/05/15 13:06:32 INFO mapreduce.Job: Running job: job_1652643101887_0005
22/05/15 13:07:21 INFO mapreduce.Job: Job job_1652643101887_0005
running in uber mode : false
22/05/15 13:07:21 INFO mapreduce.Job:  map 0% reduce 0%
22/05/15 13:08:10 INFO mapreduce.Job:  map 100% reduce 0%
22/05/15 13:08:43 INFO mapreduce.Job:  map 100% reduce 100%
22/05/15 13:08:44 INFO mapreduce.Job: Job job_1652643101887_0005
completed successfully
22/05/15 13:08:46 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=43
                FILE: Number of bytes written=227703
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=211
                HDFS: Number of bytes written=16
                HDFS: Number of read operations=6
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=1
                Launched reduce tasks=1
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=5540864
                Total time spent by all reduces in occupied slots (ms)=3831424
                Total time spent by all map tasks (ms)=43288
                Total time spent by all reduce tasks (ms)=29933
                Total vcore-seconds taken by all map tasks=43288
                Total vcore-seconds taken by all reduce tasks=29933
                Total megabyte-seconds taken by all map tasks=5540864
                Total megabyte-seconds taken by all reduce tasks=3831424
        Map-Reduce Framework
                Map input records=5
                Map output records=5
                Map output bytes=75
                Map output materialized bytes=39
                Input split bytes=131
                Combine input records=5
                Combine output records=5
                Reduce input groups=1
                Reduce shuffle bytes=39
                Reduce input records=5
                Reduce output records=1
                Spilled Records=10
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=504
                CPU time spent (ms)=3500
                Physical memory (bytes) snapshot=219488256
                Virtual memory (bytes) snapshot=1412214784
                Total committed heap usage (bytes)=101449728
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=80
        File Output Format Counters
                Bytes Written=16
[cloudera@quickstart ~]$ hadoop fs -cat output2/part-r-00000
^C[cloudera@quickstart ~]$ hadoop fs -cat output2/part-r-00000
10.128.2.1      4257
[cloudera@quickstart ~]$